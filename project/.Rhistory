rm(list = ls())
set.seed(123)
n <- 20
group <- rep(c("Treatment", "Control"), each = n)
time <- rep(c("Pre", "Post"), each = n)
performance <- c(rnorm(n, mean = 50, sd = 10), rnorm(n, mean = 60, sd = 10))
data <- data.frame(Group = group, Time = time, Performance = performance)
str(data)
anova_result <- aov(Performance ~ Group * Time, data = data)
summary(anova_result)
data
require(tidyverse)
install.packages("rstatix")
require(tidyverse); require(rstatix)
?anova_test
rstatix
require(tidyverse); require(rstatix)
knitr::opts_chunk$set(echo = TRUE)
require(tidyverse)
attach(data <- read_delim("Data.txt"))
head(data)
require(lme4)
lmer(OV ~ ASTALLX5 + EE + DP + PA + OSTES + CM + SE + Choice + IS + Group + (1 | ID))
attach(data <- read_delim("Data.txt"))
head(data)
View(data)
colnames(data)
lmer(OVS ~ ASTALLX5 + EET + DPT + PAT + OSTEST + CMT + SET + Choice + IST + Group + (1 | ID))
require(nlme)
knitr::opts_chunk$set(echo = TRUE)
require(tidyverse)
require(lme4)
require(nlme)
lme(OVS ~ ASTALLX5 + EET + DPT + PAT + OSTEST + CMT + SET + Choice + IST + Group,
random = ~ 1 | ID)
m1 <- lme(OVS ~ ASTALLX5 + EET + DPT + PAT + OSTEST + CMT + SET + Choice + IST + Group,
random = ~ 1 | ID)
anova(m1)
m1 <- lme(OVS ~ ASTALLX5 + EET + DPT + PAT + OSTEST + CMT + SET + Choice + IST + Group,
random = ~ 1 | ID)
anova(m1)
lme(ASTALLX5 ~ Phase + Group, random = ~ 1 | ID)
anova(lme(ASTALLX5 ~ Phase + Group, random = ~ 1 | ID))
data %>% group_by(Phase, Group)
data %>% group_by(Phase, Group) %>%
summarise_at(vars(pts), list(name = mean))
data %>% group_by(Phase, Group) %>%
summarise_at(vars(ASTALLX5), list(name = mean))
knitr::opts_chunk$set(echo = TRUE)
require(tidyverse)
require(lme4)
require(nlme)
data %>% group_by(Phase, Group) %>%
summarise_at(vars(ASTALLX5), list(name = mean))
require(nlme)
attach(data <- read_delim("Data.txt"))
data %>% group_by(Phase, Group) %>%
summarise_at(vars(ASTALLX5), list(name = mean))
m1 <- lme(OVS ~ ASTALLX5 + EET + DPT + PAT + OSTEST + CMT + SET + Choice + IST + Group,
random = ~ 1 | ID)
anova(m1)
m1
m2 <- lme(OVS ~ ASTALLX5 + Phase + EET + DPT + PAT +
OSTEST + CMT + SET + Choice + IST + Group,
random = ~ 1 | ID)
anova(m2)
unique(Choice)
m
attach(data <- read_delim("Data.txt"))
m1 <- lme(OVS ~ ASTALLX5 + EET + DPT + PAT + OSTEST + CMT + SET + Choice + IST + Group,
random = ~ 1 | ID)
anova(m1)
m2 <- lme(OVS ~ ASTALLX5 + Phase + EET + DPT + PAT +
OSTEST + CMT + SET + Choice + IST + Group,
random = ~ 1 | ID)
anova(m2)
plot(m2)
plot(m2)
qqplot(m2)
qqnorm(resid(m1))
qqline(resid(m1))
qqnorm(resid(m1))
qqnorm(resid(m2))
abline(1, 0)
qqnorm(resid(m2))
abline(1, 0)
qqnorm(resid(m2))
abline(h=0, v=1)
qqnorm(resid(m2))
abline(h=0)
?abline
abline(h=0, b=1)
qqnorm(resid(m2))
abline(h=0, b=1)
hist(resid(m2))
qqnorm(resid(m2))
abline(a = 0, b = 1)
abline(a = 0, b = 1, col = "r")
qqnorm(resid(m2))
abline(a = 0, b = 1, col = "r")
qqnorm(resid(m2))
abline(a = 0, b = 1, col = "red")
z <- local({
x<-10;
y<-15;
x + y;
})
z
z2 <- {
x <- 10;
y <- 15;
x + y;
}
z2
x <- 100
z2
y
z <- local({
x<-10;
y<-15;
x + y;
})
z2 <- {
x <- 10;
y <- 15;
x + y;
}
x <- 10
z <- local({
y<-15;
x + y;
})
z
list_of_functions <- list();
list_of_functions <- list();
list_of_functions <- list();
for(i in 1:10){
list_of_functions <- c(list_of_functions, function() i);
}
for(f in list_of_functions){
print(f());
}
list_of_functions <- list();
for(i in 1:10){
list_of_functions <<- c(list_of_functions, function() i);
}
for(f in list_of_functions){
print(f());
}
list_of_functions <- list();
for(i in 1:10){
list_of_functions <- c(list_of_functions, function() i);
}
list_of_functions
list_of_functions <- list();
for(i in 1:10){
# list_of_functions <- c(list_of_functions, function() i);
c(list_of_functions, function() i);
}
list_of_functions <- list();
for(i in 1:10){
list_of_functions <- c(list_of_functions, i);
}
for(f in list_of_functions){
print(f());
}
list_of_functions <- list();
for(i in 1:10){
list_of_functions <- c(list_of_functions, i);
}
for(f in list_of_functions){
print(f);
}
?eval
with_list <- function(val_list, expr) {
eval(expr, substitute(val_list))
}
q <- 7;
with_list(list(x=10,y=100),{
x + y + q;
});
substitute(list(x=10,y=100))
eval(x, substitute(list(x=10,y=100)))
with_list <- function(val_list, expr) {
eval(substitute(expr), val_list)
}
q <- 7;
with_list(list(x=10,y=100),{
x + y + q;
});
eval("x+y", list(x=10,y=100))
# 5 samples
total.interval <- c(60, 50, 60, 60, 70)
engaged.interval <- c(10, 5, 40, 20, 70)
ast <- c(1, 2, 3, 4, 5)
cbind(engage.interval, total.interval)
# 5 samples
total.interval <- c(60, 50, 60, 60, 70)
engaged.interval <- c(10, 5, 40, 20, 70)
ast <- c(1, 2, 3, 4, 5)
cbind(engage.interval, total.interval)
cbind(engaged.interval, total.interval)
binded <- cbind(engaged.interval, total.interval)
glm(binded ~ ast)
glm(binded ~ ast, family=binomial)
binded
install.packages("lme4")
require(lme4)
lmer(
binded ~ ast,
family=binomial,
)
glmer(
binded ~ ast,
family=binomial,
)
id <- c("1", "2", "1", "2", "1")
glmer(
binded ~ ast + (1|id),
family=binomial,
)
require(tidyverse)
# read in data and print problem
raw.data <- read_csv("NYC_Dog_Licensing_Dataset_20240918.csv", show_col_types = F)
pr <- problems(raw.data)
print(pr)
# rename the columns
data <- raw.data %>%
rename(
name=AnimalName,
gender=AnimalGender,
birth_year=AnimalBirthYear,
breed=BreedName,
zipcode=ZipCode,
issue_date=LicenseIssuedDate,
expiration_date=LicenseExpiredDate,
extract_year=`Extract Year`
)
# reduce to complete case
sprintf("%d rows before filtering complete cases", nrow(data))
data <- data %>% filter(complete.cases(.))
sprintf("%d rows after filtering complete cases", nrow(data))
distinct.data <- data %>% distinct()
write_csv(distinct.data, "distinct_data.csv")
sprintf("%d distinct rows", nrow(distinct.data))
# extract duplicated rows
duplicated <- data %>% group_by_all() %>% filter(n() > 1) %>% distinct()
print(duplicated)
name.count <- duplicated %>%
group_by(name) %>%
summarise(n=n())
print(name.count[1:5,])
print(arrange(name.count, desc(n))[1:5,])
ggplot(distinct.data, aes(birth_year)) + geom_histogram(stat="count") +
labs(x="Birth year", y="Dog count", title="All year dog count")
ggsave("dog_count_all.pdf")
nontrivial.years <- distinct.data %>%
group_by(birth_year) %>%
summarise(count=n()) %>%
filter(count > 20)
distinct.data %>%
filter(birth_year %in% nontrivial.years$birth_year) %>%
ggplot(aes(birth_year)) + geom_histogram(stat="count") +
labs(x="Birth year", y="Dog count", title="Nontrivial year dog count")
ggsave("dog_count_nontrivial.pdf")
sprintf("%d rows before filtered by name, gender, birth year, breed, and zip code",
nrow(distinct.data))
unique.data <- distinct.data %>%
distinct(name, gender, birth_year, breed, zipcode)
sprintf("%d rows after filtered by name, gender, birth year, breed, and zip code",
nrow(unique.data))
write_csv(unique.data, "unique.csv")
dogs.by.year <- unique.data %>%
group_by(birth_year) %>%
summarise(count=n())
dogs.by.year.name <- unique.data %>%
group_by(birth_year, name) %>%
summarise(name_count=n(), .groups = "drop")
joined.count <- dogs.by.year %>%
right_join(dogs.by.year.name, by=c("birth_year")) %>%
mutate(rate=name_count/count)
df.1999 <- joined.count[joined.count$birth_year==1999,]
max.rate.1999 <- df.1999$name[df.1999$rate==max(df.1999$rate)]
cat("The most popular dog names in 1999 are/is:",
paste(max.rate.1999, collapse = ", "))
df.2024 <- joined.count[joined.count$birth_year==2024,]
if (nrow(df.2024) == 0) {
cat("No dogs were born in 2024 in the dataset.")
} else {
max.rate.2024 <- df.2024$name[df.2024$rate==max(df.2024$rate)]
cat("The most popular dog names in 2024 are/is:",
paste(max.rate.2024, collapse = ", "))
}
joined.count %>%
filter(name %in% max.rate.1999) %>%
ggplot(aes(x=birth_year, y=rate)) +
facet_wrap(~name) +
geom_bar(stat="identity") +
labs(x="Birth year", y="Rate")
ggsave("max_name.pdf")
head(mtcars)
anova(lm(mpg ~ cyl, data=mtcars))
summary(anova(lm(mpg ~ cyl, data=mtcars)))
sum(resid(lm(mpg ~ cyl, data=mtcars)))
m <- lm(mpg ~ cyl, data=mtcars)
m
require(tidyverse)
mtcars %>% ggplot(aes(x=cyl, y=mpg)) + geom_point()
predict(m, mtcars$cyl)
predict(m, list(cyl=mtcars$cyl))
predict(m, list(cyl=mtcars$cyl)) - mtcars$mpg
sum((predict(m, list(cyl=mtcars$cyl)) - mtcars$mpg)^2)
anova(m)
with(mtcars, sum((mpg - mean(mpg))^2))
mtcars %>%
group_by(cyl) %>%
summarise(a=n(), b=sum((cyl-mean(cyl))^2))
mtcars %>%
group_by(cyl) %>%
summarise(a=n(), b=sum((mpg-mean(mpg))^2))
mtcars %>%
group_by(cyl) %>%
summarise(a=n(), b=sum((mpg-mean(mpg))^2)) %>%
mutate(c=a*b)
mtcars %>%
group_by(cyl) %>%
summarise(a=n(), b=mean(mpg))
sst_df <- mtcars %>%
group_by(cyl) %>%
summarise(a=n(), b=mean(mpg))
(sst_df$b - mean(mpg))^2
(sst_df$b - mean(mtcars@mpg))^2
(sst_df$b - mean(mtcars$mpg))^2
sst_df$a*(sst_df$b - mean(mtcars$mpg))^2
sum(sst_df$a*(sst_df$b - mean(mtcars$mpg))^2)
anova(m)
c <- (sst_df$b - mean(mtcars$mpg))^2
sum(sst_df$a*c)
sum((sst_df$a-1)*c)
sum((sst_df$a)*c)
ssr <- sum((predict(m, list(cyl=mtcars$cyl)) - mean(mtcars$mpg))^2)
ssr
require(dplyr)
repeat(rnorm(100))
rnorm(100)
repeat(rnorm(100), 5)
?repeat
?replicate
replicate(rnorm(100), 5)
replicate(5, rnorm(100))
centers <- c(
c(5,0,0,0,0),
c(-5,0,0,0,0),
c(0,0,0,3,0),
c(0,0,0,-2,0),
c(4,0,0,-3,0)
)
centers
centers <- data.frame(
c(5,0,0,0,0),
c(-5,0,0,0,0),
c(0,0,0,3,0),
c(0,0,0,-2,0),
c(4,0,0,-3,0)
)
centers
centers <- matrix(
c(5,0,0,0,0),
c(-5,0,0,0,0),
c(0,0,0,3,0),
c(0,0,0,-2,0),
c(4,0,0,-3,0)
)
kmeans_custom <- function(data, k, max_iters = 100) {
# Step 1: Randomly initialize k centroids from the data
set.seed(123)  # For reproducibility
centroids <- data[sample(nrow(data), k), ]
# Function to compute the Euclidean distance between two points
euclidean_dist <- function(a, b) {
sqrt(sum((a - b)^2))
}
# Function to assign each point to the nearest centroid
assign_clusters <- function(data, centroids) {
clusters <- sapply(1:nrow(data), function(i) {
distances <- sapply(1:k, function(j) euclidean_dist(data[i, ], centroids[j, ]))
which.min(distances)  # Assign to closest centroid
})
return(clusters)
}
# Function to update centroids based on the current cluster assignment
update_centroids <- function(data, clusters, k) {
new_centroids <- sapply(1:k, function(cluster) {
colMeans(data[clusters == cluster, , drop = FALSE], na.rm = TRUE)
})
return(t(new_centroids))  # Transpose to match centroids shape
}
# Step 2: Repeat the assignment and updating steps until convergence or max_iters
for (iter in 1:max_iters) {
# Step 2.1: Assign clusters
clusters <- assign_clusters(data, centroids)
# Step 2.2: Update centroids
new_centroids <- update_centroids(data, clusters, k)
# Step 2.3: Check for convergence (if centroids do not change)
if (all(centroids == new_centroids)) {
message("Converged in ", iter, " iterations")
break
}
# Update centroids for next iteration
centroids <- new_centroids
}
return(list(clusters = clusters, centroids = centroids))
}
# Test the algorithm with sample data
set.seed(123)
data <- matrix(rnorm(100), nrow = 50, ncol = 2)  # Random 2D data points
# Run custom K-means algorithm with 3 clusters
k <- 3
result <- kmeans_custom(data, k)
# View the resulting clusters and centroids
print(result$clusters)
print(result$centroids)
setwd("Documents/coursework/2024fall/BIOS611/project/")
knitr::opts_chunk$set(echo = TRUE)
data <- load("Layer2_BC_Count.rds")
dim(data)
length(data)
load("Layer2_BC_Count.rds")
dim(rawcount)
info <- cbind.data.frame(x=as.numeric(sapply(strsplit(colnames(rawcount),split="x"),"[",1)),
y=as.numeric(sapply(strsplit(colnames(rawcount),split="x"),"[",2)),
total_counts=apply(rawcount,2,sum))
rownames(info) <- colnames(rawcount)
info
rownames(info) <- colnames(rawcount)
